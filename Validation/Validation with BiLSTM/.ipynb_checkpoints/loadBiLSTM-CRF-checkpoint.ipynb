{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script is used to load a trained model, and then to predict negation and uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./libs')\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report as eskclarep\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from seqeval.metrics import classification_report as seqclarep\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import chain\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Concatenate, Lambda, Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, InputLayer, Activation, Flatten, Masking\n",
    "from tensorflow.keras.optimizers import Adam, schedules\n",
    "\n",
    "from tf2crf import CRF as crf6\n",
    "from mwrapper import ModelWithCRFLoss, ModelWithCRFLossDSCLoss\n",
    "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import datetime, os\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'  # TF 2.1+\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "MODEL         = 'base_model_bioEmb_300_skyp'\n",
    "logs_base_dir = \"./logs\"\n",
    "log_dir       = logs_base_dir + \"/\" + MODEL\n",
    "save_base_dir = './model-save'\n",
    "save_dir      = save_base_dir + \"/\" + MODEL\n",
    "\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "os.makedirs(log_dir,       exist_ok=True)\n",
    "os.makedirs(save_base_dir, exist_ok=True)\n",
    "os.makedirs(save_dir,      exist_ok=True)\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# ****** DEFINICION DE PARAMETROS *********\n",
    "NUM_WORDS       = 25331 + 2\n",
    "LEN_SENTS       = 190\n",
    "NUM_TAGS        = 9 + 2\n",
    "\n",
    "# ****** DEFINICION DE HIPERPARAMETROS *********\n",
    "_EPOCHS         = 60\n",
    "EMBED_DIM       = 300\n",
    "_DROPOUT        = 0.5\n",
    "_BACH_SIZE      = 512 + 256\n",
    "_LEARN_RATE     = 1e-2\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = np.load('vectors/word2index.npy', allow_pickle=True).item()\n",
    "tag2idx  = np.load('vectors/tag2index.npy', allow_pickle=True).item()\n",
    "idx2tag  = np.load('vectors/index2tag.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model\n",
    "print(\"\\nLoading the model for negation and uncertainty detection ...\")\n",
    "model = tf.saved_model.load(save_dir + \"/\")\n",
    "print (\"\\nModel loaded ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: Sentences must be previously tokenized (e.g NLTK or Spacy for spanish)\n",
    "#The model receives a tokenized sentence and returns a negation or speculation label for each token.\n",
    "#Next sentences have been proviously tokenized. \n",
    "#It is recommended to use  NLTK o r Spacy tokenizerfor spanish language.\n",
    "\n",
    "negation_samples = [\n",
    "    \"No dolor toráxico ni agudo .\".split(),\n",
    "    \"Paciente con probable carcinoma pulmonar .\".split(),\n",
    "    \"Inflamacion aguda negativa .\".split(),\n",
    "    \"helicobacter pylori negativo .\".split(),\n",
    "    \"negativo para malignidad .\".split(),\n",
    "    \"No se puede descartar cáncer de pulmón .\".split(),\n",
    "    \"Sin fiebre ni nauseas .\".split()    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_samples_X    = []\n",
    "\n",
    "for s1 in negation_samples:\n",
    "    s1_int = []\n",
    "    for w in s1:\n",
    "        try:\n",
    "            s1_int.append(word2idx[w.lower()])\n",
    "        except KeyError:\n",
    "            s1_int.append(word2idx['-OOV-'])\n",
    "    negation_samples_X.append(s1_int)\n",
    "\n",
    "negation_samples_X = pad_sequences(negation_samples_X, maxlen=LEN_SENTS, padding='post')\n",
    "\n",
    "print(\"Negation: \\n\", negation_samples_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = model(negation_samples_X).numpy()\n",
    "#print(\"Negation: \\n\", predictions1, predictions1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_tokens1 = logits_to_tokens(np.argmax(predictions1, -1), idx2tag)\n",
    "log_tokens1 = logits_to_tokens(predictions1, idx2tag)\n",
    "print (\"Sentence \" , negation_samples[0])\n",
    "print(\"Negation: \\n\", log_tokens1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h, oracc in enumerate(negation_samples):\n",
    "    heads = oracc\n",
    "    body  = [log_tokens1[h][:len(oracc)]]\n",
    "    display(HTML(\"<div style='overflow-x: auto; white-space: nowrap;'>\" + \n",
    "                 tabulate(body, headers=heads, tablefmt=\"html\") + \n",
    "                 \"</div>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
